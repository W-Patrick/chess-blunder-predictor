{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "region = sagemaker_session.boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_uri = 's3://pwalanki-blunder-predictor-data/output-2020-march'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow.keras.callbacks\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TensorBoard, EarlyStopping, ModelCheckpoint\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmath\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel\u001b[39;49;00m(training_data, validation_data, dense_layers, num_nodes, epochs, learning_rate, dropout, callback=\u001b[36mNone\u001b[39;49;00m):\r\n",
      "\tfeature_columns = [\r\n",
      "\t\ttf.feature_column.numeric_column(\u001b[33m'\u001b[39;49;00m\u001b[33mposition\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, shape=(\u001b[34m1\u001b[39;49;00m, \u001b[34m8\u001b[39;49;00m, \u001b[34m8\u001b[39;49;00m, \u001b[34m12\u001b[39;49;00m), dtype=tf.dtypes.int64),\r\n",
      "\t\ttf.feature_column.numeric_column(\u001b[33m'\u001b[39;49;00m\u001b[33mturn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, shape=(\u001b[34m1\u001b[39;49;00m,), dtype=tf.dtypes.int64),\r\n",
      "\t\ttf.feature_column.numeric_column(\u001b[33m'\u001b[39;49;00m\u001b[33melo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, shape=(\u001b[34m1\u001b[39;49;00m,), dtype=tf.dtypes.float32)\r\n",
      "\t]\r\n",
      "\r\n",
      "\tmodel = tf.keras.models.Sequential()\r\n",
      "\tmodel.add(tf.keras.layers.DenseFeatures(feature_columns))\r\n",
      "\r\n",
      "\t\u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(dense_layers):\r\n",
      "\t\tmodel.add(tf.keras.layers.Dense(num_nodes, activation=tf.nn.relu))\r\n",
      "\r\n",
      "\tmodel.add(tf.keras.layers.Dropout(dropout))\r\n",
      "\r\n",
      "\tmodel.add(tf.keras.layers.Dense(\u001b[34m1\u001b[39;49;00m, activation=tf.nn.sigmoid))\r\n",
      "\r\n",
      "\tmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\r\n",
      "\t\t\t\t  loss=\u001b[33m'\u001b[39;49;00m\u001b[33mbinary_crossentropy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "\t\t\t\t  metrics=[\u001b[33m'\u001b[39;49;00m\u001b[33maccuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, tf.metrics.Recall(), tf.metrics.Precision()])\r\n",
      "\r\n",
      "\tmodel.fit(training_data,\r\n",
      "\t\t\t  validation_data=validation_data,\r\n",
      "\t\t\t  epochs=epochs,\r\n",
      "\t\t\t  callbacks=callbacks)\r\n",
      "\r\n",
      "\t\u001b[34mreturn\u001b[39;49;00m model\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_parse_function\u001b[39;49;00m(raw_data):\r\n",
      "\tfeature_description = {\r\n",
      "\t\t\u001b[33m'\u001b[39;49;00m\u001b[33mposition\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: tf.io.FixedLenFeature((), tf.string),\r\n",
      "\t\t\u001b[33m'\u001b[39;49;00m\u001b[33mturn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: tf.io.FixedLenFeature((), tf.int64),\r\n",
      "\t\t\u001b[33m'\u001b[39;49;00m\u001b[33melo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: tf.io.FixedLenFeature((), tf.float32),\r\n",
      "\t\t\u001b[33m'\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: tf.io.FixedLenFeature((), tf.int64)\r\n",
      "\t}\r\n",
      "\r\n",
      "\texample = tf.io.parse_single_example(raw_data, feature_description)\r\n",
      "\r\n",
      "\traw_position = example[\u001b[33m'\u001b[39;49;00m\u001b[33mposition\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "\r\n",
      "\tposition = tf.io.decode_raw(raw_position, tf.int64)\r\n",
      "\tposition = tf.reshape(position, tf.stack([\u001b[34m8\u001b[39;49;00m, \u001b[34m8\u001b[39;49;00m, \u001b[34m12\u001b[39;49;00m]))\r\n",
      "\r\n",
      "\tturn = example[\u001b[33m'\u001b[39;49;00m\u001b[33mturn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "\telo = example[\u001b[33m'\u001b[39;49;00m\u001b[33melo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "\tlabel = example[\u001b[33m'\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "\r\n",
      "\t\u001b[34mreturn\u001b[39;49;00m \u001b[36mdict\u001b[39;49;00m({\u001b[33m'\u001b[39;49;00m\u001b[33mposition\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [position], \u001b[33m'\u001b[39;49;00m\u001b[33melo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [elo], \u001b[33m'\u001b[39;49;00m\u001b[33mturn\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [turn]}), [label]\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mload_datasets\u001b[39;49;00m(training_data_paths, validation_data_paths, test_data_paths):\r\n",
      "\traw_dataset = tf.data.TFRecordDataset(training_data_paths)\r\n",
      "\ttrain_ds = raw_dataset.map(_parse_function)\r\n",
      "\ttrain_ds = train_ds.shuffle(buffer_size=\u001b[34m256\u001b[39;49;00m)\r\n",
      "\r\n",
      "\traw_validation_set = tf.data.TFRecordDataset(validation_data_paths)\r\n",
      "\tval_ds = raw_validation_set.map(_parse_function)\r\n",
      "\tval_ds = val_ds.shuffle(buffer_size=\u001b[34m256\u001b[39;49;00m)\r\n",
      "\r\n",
      "\traw_test_dataset = tf.data.TFRecordDataset(test_data_paths)\r\n",
      "\ttest_ds = raw_test_dataset.map(_parse_function)\r\n",
      "\ttest_ds = test_ds.shuffle(buffer_size=\u001b[34m256\u001b[39;49;00m)\r\n",
      "\r\n",
      "\t\u001b[34mreturn\u001b[39;49;00m train_ds, val_ds, test_ds\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mload_part\u001b[39;49;00m(part, s3_url, aws, namespace):\r\n",
      "\tpart_prefix = \u001b[33m'\u001b[39;49;00m\u001b[33mpart-r-\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "\tpart_suffix = \u001b[36mstr\u001b[39;49;00m(part)\r\n",
      "\t\u001b[34mwhile\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(part_suffix) < \u001b[34m5\u001b[39;49;00m: part_suffix = \u001b[33m'\u001b[39;49;00m\u001b[33m0\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + part_suffix\r\n",
      "\tpart_file = part_prefix + part_suffix\r\n",
      "\r\n",
      "\turl = \u001b[33m'\u001b[39;49;00m\u001b[33m{}/{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(s3_url, part_file)\r\n",
      "\r\n",
      "\t\u001b[37m# check if we are on sagemaker\u001b[39;49;00m\r\n",
      "\t\u001b[34mif\u001b[39;49;00m aws:\r\n",
      "\t\tfile_path = url\r\n",
      "\t\u001b[34melse\u001b[39;49;00m:\r\n",
      "\t\tfile_path = tf.keras.utils.get_file(\u001b[33m'\u001b[39;49;00m\u001b[33m{}.{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(namespace, part_file), url)\r\n",
      "\r\n",
      "\t\u001b[34mreturn\u001b[39;49;00m file_path\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mload_remote_training_data\u001b[39;49;00m(s3_url, parts, aws, namespace=\u001b[33m'\u001b[39;49;00m\u001b[33mmain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\r\n",
      "\t\u001b[34mif\u001b[39;49;00m parts < \u001b[34m3\u001b[39;49;00m:\r\n",
      "\t\t\u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mThere must be at least 3 parts in the dataset\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "\ttraining_split = .\u001b[34m7\u001b[39;49;00m\r\n",
      "\r\n",
      "\ttraining_parts_upper = \u001b[36mint\u001b[39;49;00m(parts * training_split)\r\n",
      "\ttrain_parts = \u001b[36mrange\u001b[39;49;00m(training_parts_upper)\r\n",
      "\r\n",
      "\tremaining_parts = parts - \u001b[36mlen\u001b[39;49;00m(train_parts)\r\n",
      "\tnum_validation_parts = math.ceil(remaining_parts / \u001b[34m2\u001b[39;49;00m)\r\n",
      "\tvalidation_parts_upper = training_parts_upper + num_validation_parts\r\n",
      "\r\n",
      "\tval_parts = \u001b[36mrange\u001b[39;49;00m(training_parts_upper, validation_parts_upper)\r\n",
      "\ttest_parts = \u001b[36mrange\u001b[39;49;00m(validation_parts_upper, parts)\r\n",
      "\r\n",
      "\ttraining_data = []\r\n",
      "\t\u001b[34mfor\u001b[39;49;00m part \u001b[35min\u001b[39;49;00m train_parts:\r\n",
      "\t\tfile_path = load_part(part, s3_url, aws, namespace)\r\n",
      "\t\ttraining_data.append(file_path)\r\n",
      "\r\n",
      "\tvalidation_data = []\r\n",
      "\t\u001b[34mfor\u001b[39;49;00m part \u001b[35min\u001b[39;49;00m val_parts:\r\n",
      "\t\tval_file_path = load_part(part, s3_url, aws, namespace)\r\n",
      "\t\tvalidation_data.append(val_file_path)\r\n",
      "\r\n",
      "\ttest_data = []\r\n",
      "\t\u001b[34mfor\u001b[39;49;00m part \u001b[35min\u001b[39;49;00m test_parts:\r\n",
      "\t\ttest_file_path = load_part(part, s3_url, aws, namespace)\r\n",
      "\t\ttest_data.append(test_file_path)\r\n",
      "\r\n",
      "\t\u001b[34mreturn\u001b[39;49;00m load_datasets(training_data, validation_data, test_data)\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mevaluate_model\u001b[39;49;00m(model, test_ds, model_name=\u001b[33m'\u001b[39;49;00m\u001b[33mmodel\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\r\n",
      "\ttest_loss, test_acc, test_recall, test_precision = model.evaluate(test_ds)\r\n",
      "\t\u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m{}: test_loss={} test_acc={} test_recall={} test_precision={}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(model_name, test_loss, test_acc, test_recall, test_precision))\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mparse_args\u001b[39;49;00m():\r\n",
      "\tparser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--aws\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mbool\u001b[39;49;00m, default=\u001b[36mFalse\u001b[39;49;00m)\r\n",
      "\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1000\u001b[39;49;00m)\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m)\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--parts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33m3\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--learning-rate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=.\u001b[34m00001\u001b[39;49;00m)\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--dense-layers\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m2\u001b[39;49;00m)\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--num-nodes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1024\u001b[39;49;00m)\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--dropout\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.2\u001b[39;49;00m)\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--tensorboard\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mbool\u001b[39;49;00m, default=\u001b[36mFalse\u001b[39;49;00m)\r\n",
      "\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--sm-model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mif\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[35min\u001b[39;49;00m os.environ \u001b[34melse\u001b[39;49;00m \u001b[36mNone\u001b[39;49;00m)\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m)\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)) \u001b[34mif\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[35min\u001b[39;49;00m os.environ \u001b[34melse\u001b[39;49;00m \u001b[36mNone\u001b[39;49;00m)\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mif\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[35min\u001b[39;49;00m os.environ \u001b[34melse\u001b[39;49;00m \u001b[36mNone\u001b[39;49;00m)\r\n",
      "\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--early-stopping\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mbool\u001b[39;49;00m, default=\u001b[36mFalse\u001b[39;49;00m)\r\n",
      "\tparser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--patience\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m100\u001b[39;49;00m)\r\n",
      "\r\n",
      "\t\u001b[34mreturn\u001b[39;49;00m parser.parse_args()\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "\targs = parse_args()\r\n",
      "\r\n",
      "\tmodel_output_dir = args.sm_model_dir \u001b[34mif\u001b[39;49;00m args.sm_model_dir \u001b[35mis\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[36mNone\u001b[39;49;00m \u001b[34melse\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mmodels\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "\tmodel_output_fp = os.path.join(model_output_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mblunder-predictor.model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\tmodel_best_acc_fp = os.path.join(model_output_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mbest-accuracy.model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\tmodel_best_recall_fp = os.path.join(model_output_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mbest-recall.model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "\t\u001b[37m# need to check the environment variables here because they are slightly different depending\u001b[39;49;00m\r\n",
      "\t\u001b[37m# on whether you are running a regular training or a tuning job\u001b[39;49;00m\r\n",
      "\t\u001b[34mif\u001b[39;49;00m args.train \u001b[35mis\u001b[39;49;00m \u001b[36mNone\u001b[39;49;00m:\r\n",
      "\t\t\u001b[34mif\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[35min\u001b[39;49;00m os.environ:\r\n",
      "\t\t\ttrain = os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\t\t\u001b[34melif\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[35min\u001b[39;49;00m os.environ:\r\n",
      "\t\t\ttrain = os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAIN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\t\t\u001b[34melse\u001b[39;49;00m:\r\n",
      "\t\t\ttrain = args.train\r\n",
      "\t\u001b[34melse\u001b[39;49;00m:\r\n",
      "\t\ttrain = args.train\r\n",
      "\r\n",
      "\t\u001b[37m# load all datasets\u001b[39;49;00m\r\n",
      "\ttrain_ds, val_ds, test_ds = load_remote_training_data(train, \u001b[36mint\u001b[39;49;00m(args.parts), args.aws)\r\n",
      "\r\n",
      "\t\u001b[37m# batch the datasets\u001b[39;49;00m\r\n",
      "\ttrain_ds = train_ds.batch(args.batch_size)\r\n",
      "\tval_ds = val_ds.batch(args.batch_size)\r\n",
      "\ttest_ds = test_ds.batch(args.batch_size)\r\n",
      "\r\n",
      "\t\u001b[37m# define callbacks\u001b[39;49;00m\r\n",
      "\tcallbacks = []\r\n",
      "\r\n",
      "\t\u001b[34mif\u001b[39;49;00m args.early_stopping:\r\n",
      "\t\t\u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mEARLY STOPPING IS TURNED ON\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\t\tearly_stopping = EarlyStopping(monitor=\u001b[33m'\u001b[39;49;00m\u001b[33mval_loss\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, mode=\u001b[33m'\u001b[39;49;00m\u001b[33mmin\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, verbose=\u001b[34m1\u001b[39;49;00m, patience=args.patience)\r\n",
      "\t\t\r\n",
      "\t\taccuracy_checkpoint = ModelCheckpoint(\r\n",
      "\t\t\tmodel_best_acc_fp, monitor=\u001b[33m'\u001b[39;49;00m\u001b[33mval_accuracy\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, mode=\u001b[33m'\u001b[39;49;00m\u001b[33mmax\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, verbose=\u001b[34m1\u001b[39;49;00m, save_best_only=\u001b[36mTrue\u001b[39;49;00m) \r\n",
      "\r\n",
      "\t\trecall_checkpoint = ModelCheckpoint(\r\n",
      "\t\t\tmodel_best_recall_fp, monitor=\u001b[33m'\u001b[39;49;00m\u001b[33mval_recall\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, mode=\u001b[33m'\u001b[39;49;00m\u001b[33mmax\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, verbose=\u001b[34m1\u001b[39;49;00m, save_best_only=\u001b[36mTrue\u001b[39;49;00m)\r\n",
      "\r\n",
      "\t\tcallbacks.append(early_stopping)\r\n",
      "\t\tcallbacks.append(accuracy_checkpoint)\r\n",
      "\t\tcallbacks.append(recall_checkpoint)\r\n",
      "\r\n",
      "\t\u001b[34mif\u001b[39;49;00m args.tensorboard:\r\n",
      "\t\tname = \u001b[33m'\u001b[39;49;00m\u001b[33mITERATION-7-HYPERTUNING-blunder-predictor-{}-batch-{}-dense-{}-nodes-{}-dropout-{}-learning-rate-{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\r\n",
      "\t\t\targs.batch_size, args.dense_layers, args.num_nodes, args.dropout, args.learning_rate, \u001b[36mint\u001b[39;49;00m(time.time()))\r\n",
      "\r\n",
      "\t\ttensorboard = TensorBoard(log_dir=\u001b[33m'\u001b[39;49;00m\u001b[33mC:\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33mlogs\u001b[39;49;00m\u001b[33m\\\\\u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(name))\r\n",
      "\t\tcallbacks.append(tensorboard)\r\n",
      "\r\n",
      "\t\u001b[37m# create and train the model\u001b[39;49;00m\r\n",
      "\tmodel = model(train_ds, val_ds, args.dense_layers, args.num_nodes, args.epochs, args.learning_rate, args.dropout, callbacks)\r\n",
      "\t\r\n",
      "\t\u001b[34mif\u001b[39;49;00m args.early_stopping:\r\n",
      "\t\t\u001b[37m# load models and evaluate\u001b[39;49;00m\r\n",
      "\t\tacc_model = tf.keras.models.load_model(model_best_acc_fp)\r\n",
      "\t\trecall_model = tf.keras.models.load_model(model_best_recall_fp)\r\n",
      "\r\n",
      "\t\tevaluate_model(acc_model, test_ds, \u001b[33m'\u001b[39;49;00m\u001b[33macc_model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\t\tevaluate_model(recall_model, test_ds, \u001b[33m'\u001b[39;49;00m\u001b[33mrecall_model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\t\u001b[34melse\u001b[39;49;00m:\r\n",
      "\t\t\u001b[37m# evaluate model\u001b[39;49;00m\r\n",
      "\t\tevaluate_model(model, test_ds)\r\n",
      "\t\r\n",
      "\t\u001b[37m# save the final model\u001b[39;49;00m\r\n",
      "\tmodel.save(model_output_fp)\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize 'model.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "\n",
    "metric_definitions = [\n",
    "    {\n",
    "        'Name': 'val_loss',\n",
    "        'Regex': 'val_loss: ([0-9\\\\.]+)'\n",
    "    },\n",
    "    {\n",
    "        'Name': 'val_accuracy',\n",
    "        'Regex': 'val_accuracy: ([0-9\\\\.]+)'\n",
    "    },\n",
    "    {\n",
    "        'Name': 'val_recall',\n",
    "        'Regex': 'val_recall: ([0-9\\\\.]+)'\n",
    "    },\n",
    "    {\n",
    "        'Name': 'val_precision',\n",
    "        'Regex': 'val_precision: ([0-9\\\\.]+)'\n",
    "    }\n",
    "]\n",
    "\n",
    "hyperparameters = {\n",
    "    'aws': True,\n",
    "    'batch-size': 64,\n",
    "    'epochs': 1000,\n",
    "    'dense-layers': 4,\n",
    "    'dropout': 0.2,\n",
    "    'learning-rate': 0.0000001,\n",
    "    'num-nodes': 2048,\n",
    "    'parts': 208,\n",
    "    'early-stopping': True  \n",
    "}\n",
    "\n",
    "estimator = TensorFlow(entry_point='model.py',\n",
    "                       role=role,\n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type='ml.m5.xlarge',\n",
    "                       framework_version='2.1.0',\n",
    "                       py_version='py3',\n",
    "                       metric_definitions=metric_definitions,\n",
    "                       hyperparameters=hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-09 04:02:08 Starting - Starting the training job...\n",
      "2020-04-09 04:02:11 Starting - Launching requested ML instances."
     ]
    }
   ],
   "source": [
    "estimator.fit(training_data_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
